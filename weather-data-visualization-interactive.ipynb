{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13176791,"sourceType":"datasetVersion","datasetId":3678699}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/headply/weather-data-visualization-interactive?scriptVersionId=264184134\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:49.202791Z","iopub.execute_input":"2025-09-26T12:29:49.202993Z","iopub.status.idle":"2025-09-26T12:29:51.854831Z","shell.execute_reply.started":"2025-09-26T12:29:49.202975Z","shell.execute_reply":"2025-09-26T12:29:51.854048Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PROJECT SUMMARY","metadata":{}},{"cell_type":"markdown","source":"**Weather & Air Quality Analysis Project**\n\n\nThis project explores a global dataset of weather conditions and air quality indicators (≈96k records), combining spatial, temporal, and environmental insights into a unified analysis.\n\n**OBJECTIVES**\n\n    Clean and preprocess weather & air quality data.\n    \n    Engineer features like day length and seasonal breakdowns.\n    \n    Explore global geospatial patterns in weather and pollution.\n    \n    Assess weather–pollution interactions (temperature, humidity, wind).\n    \n    Benchmark pollutant levels against WHO standards to identify hotspots.\n    \n    Build interactive visualizations for exploration.\n\n    \n\n**KEY ANALYSIS**\n\n    Data Cleaning & Preparation\n    \n    Standardized time-based features (sunrise, sunset, moonrise, moonset).\n    \n    Removed redundancies (e.g., °C vs °F, mph vs kph).\n    \n    Identified and managed outliers (Chile’s extreme PM2.5 events).\n    \n    Engineered features like day length (hours) and seasonal groupings.\n    \n    Exploratory Data Analysis (EDA)\n    \n    Distributions: Histograms, KDE plots, and boxplots for pollutants & weather.\n    \n    Geospatial patterns: Choropleth maps (temperature, humidity, AQI) and hotspot detection.\n    \n    Seasonality: Time-series of temperature vs PM2.5 across months.\n    \n    Weather–Pollution Interaction:\n    \n    Correlation heatmaps (temp, humidity, AQI).\n    \n    Scatter plots of wind speed vs pollutants.\n    \n    Pollutant distribution by wind direction.\n    \n    Astronomical impacts: Relationship between day length, moon phase, and visibility/temperature.\n    \n\n\n**ADVANCED INSIGHTS**\n\n    Identified countries exceeding WHO thresholds for PM2.5 and other pollutants.\n    \n    Found strong seasonal patterns (e.g., pollution spikes in dry months).\n    \n    Evidence of wind dispersal effects—higher wind speeds reduce PM2.5 concentrations.\n\n\n\n**TOOLS AND LIBRARIES**\n\n    Python (Pandas, NumPy) – data cleaning & feature engineering.\n    \n    Matplotlib / Seaborn / Plotly – static & interactive visualizations.\n    \n    GeoPandas / Folium – geospatial mapping.\n    \n    ipywidgets – dropdowns & interactive filtering in Jupyter Notebook.\n\n\n\n\n**OUTCOMES**\n\n    A reproducible notebook that combines statistical, temporal, and geospatial analysis.\n\n    Clear identification of pollution hotspots and weather patterns.\n    \n    Interactive visualizations for exploring seasonal and spatial dynamics.\n    \n    A framework adaptable for climate research, urban planning, or environmental monitoring.","metadata":{}},{"cell_type":"markdown","source":"# **1. SETUP AND IMPORTS**\n\nNote: There are some visualization in this notebook that are interactive, you can download the notebook to interact with them","metadata":{}},{"cell_type":"code","source":"#Importing necessary Libraries (not all used library are imported at this point, some are imported are the point of usage so as to show what they are used for\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns #for visualization\nimport geopandas as gpd #map visuals\nimport ipywidgets as widgets\nfrom ipywidgets import interact\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:51.85604Z","iopub.execute_input":"2025-09-26T12:29:51.85651Z","iopub.status.idle":"2025-09-26T12:29:54.9189Z","shell.execute_reply.started":"2025-09-26T12:29:51.85649Z","shell.execute_reply":"2025-09-26T12:29:54.918318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)  #To ignore every \"futurewarning\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:54.91976Z","iopub.execute_input":"2025-09-26T12:29:54.920146Z","iopub.status.idle":"2025-09-26T12:29:54.924704Z","shell.execute_reply.started":"2025-09-26T12:29:54.920123Z","shell.execute_reply":"2025-09-26T12:29:54.924014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#importing the data\n\ndf = pd.read_csv(\"/kaggle/input/global-weather-repository/GlobalWeatherRepository.csv\") #reads the csv data into a panda dataframe\ndf.head() #shows the first five rows of the dataframe by default","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:54.926836Z","iopub.execute_input":"2025-09-26T12:29:54.927112Z","iopub.status.idle":"2025-09-26T12:29:55.969081Z","shell.execute_reply.started":"2025-09-26T12:29:54.927084Z","shell.execute_reply":"2025-09-26T12:29:55.968335Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DATA UNDERSTANDING","metadata":{}},{"cell_type":"markdown","source":"Next we need to check the shape of our data to know how many rows and columns we are dealing with here.\n","metadata":{}},{"cell_type":"code","source":"#Next we need to check the shape of our data to know how many rows and columns we are dealing with here and also see if there are duplicates or missing values\n\n\ndef data_details(df):\n    shapes = df.shape #stores a tuple that corresponds with the number of rows and cols in the dataset\n    numerical_columns = df.select_dtypes(include=\"number\").shape[1] #stores the number of cols in the data that are numerical\n    non_numerical_columns =  df.select_dtypes(exclude=\"number\").shape[1] #stores the number of cols in the data that are non numerical\n    total_distinct_countries = df[\"country\"].nunique() #stores the number of distinct country names in the dataset\n    missing = df.isnull().sum() #stores total number of rows with null values\n    missing_filtered = missing[missing > 0] #returns the the specific rows with null values\n    if not missing_filtered.empty:\n        missing_report = (missing_filtered)\n    else:\n        missing_report = (\"No missing values found.\")\n    \n    duplicate_report = df.duplicated().sum()\n\n    print(f\"Total missing values = {missing_report}\\nTotal duplicates = {duplicate_report}\\nNo of rows = {shapes[0]}\\nNo of columns = {shapes[1]} \\nNumerical columns = {numerical_columns}\\nNon-numerical columns = {non_numerical_columns}\\nTotal Number of Countries = {total_distinct_countries}\")\n\ndata_details(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:55.969872Z","iopub.execute_input":"2025-09-26T12:29:55.970114Z","iopub.status.idle":"2025-09-26T12:29:56.165024Z","shell.execute_reply.started":"2025-09-26T12:29:55.970096Z","shell.execute_reply":"2025-09-26T12:29:56.164392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#let's see the the names of the columns we have their types respectively\n\ndf.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:56.165826Z","iopub.execute_input":"2025-09-26T12:29:56.166107Z","iopub.status.idle":"2025-09-26T12:29:56.235279Z","shell.execute_reply.started":"2025-09-26T12:29:56.166084Z","shell.execute_reply":"2025-09-26T12:29:56.234439Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DATA CLEANING","metadata":{}},{"cell_type":"code","source":"\"\"\"\nWhile exploring the data, some issues were highlighted such as:\nMisspelt country names and location names\nThe time column is in object type but it should be in datetime so time series information can be efficiently deduced\n\"\"\"\n\n\ndef time_normalization(df):\n    \"\"\"\n    converts the time column to a datetime type\n    \"\"\"\n    df['last_updated'] = pd.to_datetime(df['last_updated'], errors='coerce')\n    df = df.dropna(subset=['last_updated'])\n    df = df.drop_duplicates()\n    return df\n\ndef country_correction(df): #to correct mispelt country names\n    country_fix = {\n        'كولومبيا': 'Colombia',\n        '火鸡': 'Turkey',\n        'Польша': 'Poland',\n        'Турция': 'Turkey',\n        'Jemen': 'Yemen',\n        'Turkménistan': 'Turkmenistan',\n        'Bélgica': 'Belgium',\n        'Südkorea': 'South Korea',\n        'Marrocos': 'Morocco',\n        'Inde': 'India',\n        'Polônia': 'Poland',\n        'Mexique': 'Mexico',\n        'Saint-Vincent-et-les-Grenadines': 'Saint Vincent and the Grenadines',\n        'Saudi Arabien': 'Saudi Arabia',\n        'Letonia': 'Latvia',\n        'Estonie': 'Estonia',\n        'Komoren': 'Comoros',\n        'Malásia': 'Malaysia',\n        'USA United States of America': 'United States of America',\n        'Congo': 'Democratic Republic of Congo',\n        'Гватемала': 'Guatemala'\n    }\n    df['country'] = df['country'].replace(country_fix)\n    return df\n    \ndef location_correction(df): #to correct mispelt location names\n    location_fix ={\n    \"'S Gravenjansdyk\": \"'S Gravenjansdijk\",\n    \"'S Gravenstaffel\": \"'S Gravenjansdijk\",\n    \"Phnum Penh\": \"Phnom Penh\",\n    \"Beijing Shi\": \"Beijing\",\n    \"Addis Abeba\": \"Addis Ababa\",\n    \"New Guatemala\": \"Guatemala City\",\n    \"Kuwait\": \"Kuwait City\",\n    \"Mexico (Grupo Mexico)\": \"Mexico City\",\n    \"City Of San Marino\": \"San Marino\",\n    \"Ar Riyadh\": \"Riyadh\",\n    \"Nuku'alofa\": \"Nuku`Aloia\",\n    \"-Kingdom\": \"Ankara\"\n    }\n    df['location_name'] = df['location_name'].replace(location_fix)\n    return df\n    \ndef clean_weather_data(df): #returns the cleaned dataset\n    df = time_normalization(df)\n    df = country_correction(df)\n    df = location_correction(df)\n    return df\n\n\n\ndf = clean_weather_data(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:56.236079Z","iopub.execute_input":"2025-09-26T12:29:56.236411Z","iopub.status.idle":"2025-09-26T12:29:56.51206Z","shell.execute_reply.started":"2025-09-26T12:29:56.23639Z","shell.execute_reply":"2025-09-26T12:29:56.51149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#let's see if the changes we made took effect\n\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:56.512668Z","iopub.execute_input":"2025-09-26T12:29:56.51286Z","iopub.status.idle":"2025-09-26T12:29:56.533804Z","shell.execute_reply.started":"2025-09-26T12:29:56.512843Z","shell.execute_reply":"2025-09-26T12:29:56.533102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nFurthermore, to effectively make use of the sunrise and sunset column information, we need to normalize it to datetime and also ensure it connects with the actual time column.\nAlso some columns would be derived from existing columns e,g the day, month and day_time_length.\n\"\"\"\n\n\ndef sun_moon(df):\n    # Helper function to safely combine date + time\n    def safe_to_datetime(date_series, time_series):\n        return pd.to_datetime(\n            date_series.astype(str) + \" \" + time_series.astype(str),\n            format=\"%Y-%m-%d %I:%M %p\",  # enforce consistent AM/PM parsing\n            errors=\"coerce\"              # turn \"No moonrise\"/bad values into NaT\n        )\n\n    # Combine last_updated date with times\n    df[\"sunrise_dt\"] = safe_to_datetime(df[\"last_updated\"].dt.date, df[\"sunrise\"])\n    df[\"sunset_dt\"]  = safe_to_datetime(df[\"last_updated\"].dt.date, df[\"sunset\"])\n\n    # Compute durations only where valid\n    df[\"day_length_hours\"] = (df[\"sunset_dt\"] - df[\"sunrise_dt\"]).dt.total_seconds() / 3600\n    \n    return df\n\n    # add engineered durations\n    df[\"day_length_hours\"] = (df[\"sunset_dt\"] - df[\"sunrise_dt\"]).dt.total_seconds() / 3600\n    df[\"moonlight_hours\"] = (df[\"moonset_dt\"] - df[\"moonrise_dt\"]).dt.total_seconds() / 3600\n    \n    return df\n\ndef year_month_day_extraction(df):\n    df[\"year\"] = df[\"last_updated\"].dt.year\n    df[\"month_name\"] = df[\"last_updated\"].dt.strftime(\"%B\")\n    df[\"day_name\"] = df[\"last_updated\"].dt.strftime(\"%A\")\n    return df\n\ndef drop_redundant(df):\n    df.drop([\"sunrise\",\n             \"sunset\",\n             \"moonrise\",\n             \"moonset\", \n             \"last_updated_epoch\", \n             \"temperature_fahrenheit\", \n             \"wind_kph\", \n             \"pressure_in\", \n             \"precip_in\", \n             \"visibility_miles\", \n             \"feels_like_fahrenheit\", \n             \"gust_kph\"],\n            axis=1, \n            inplace=True\n           )\n    return df\n\ndef columns_creation(df):\n    df = sun_moon(df)\n    df = year_month_day_extraction(df)\n    df = drop_redundant(df)\n    return df\n\n# Apply\ndf = columns_creation(df)\n\n#let's see if the necessary columns have been dropped\ndata_details(df)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:56.534664Z","iopub.execute_input":"2025-09-26T12:29:56.534933Z","iopub.status.idle":"2025-09-26T12:29:58.115976Z","shell.execute_reply.started":"2025-09-26T12:29:56.53491Z","shell.execute_reply":"2025-09-26T12:29:58.115208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#let's see if we are good to go\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:58.118314Z","iopub.execute_input":"2025-09-26T12:29:58.118533Z","iopub.status.idle":"2025-09-26T12:29:58.138666Z","shell.execute_reply.started":"2025-09-26T12:29:58.118516Z","shell.execute_reply":"2025-09-26T12:29:58.138004Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DETECTING AND TREATING OUTLIERS\n","metadata":{}},{"cell_type":"code","source":"#Lets generate a boxplot accross all numerical columns so as to have a quick glimpse if our data realy has outliers\n\nimport matplotlib.pyplot as plt\n\nnum_cols = df.select_dtypes(include=\"number\")\n\nplt.figure(figsize=(12, 6))\nnum_cols.boxplot(rot=90)\nplt.title(\"Outlier Detection Across Numeric Columns\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:29:58.139524Z","iopub.execute_input":"2025-09-26T12:29:58.139802Z","iopub.status.idle":"2025-09-26T12:30:00.380593Z","shell.execute_reply.started":"2025-09-26T12:29:58.13976Z","shell.execute_reply":"2025-09-26T12:30:00.379891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nSpotted, our data has so many outliers, lets see them.\nFirst you either choose \"all\" or a partiular country name to see how outliers are distributed accross numerical columns,\nthen afterwards a dropdown populated with the top 10 columns with the highest outliers is provided so as to choose and see the normalization of the column.\n\"\"\"\n\nfrom ipywidgets import interact\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# --- First part: skewness per country ---\n@interact(selected_country = [\"All\"] + sorted(df[\"country\"].unique()))\ndef kde_by_country(selected_country):\n    if selected_country == \"All\":\n        filtered_df = df.copy()\n    else:\n        filtered_df = df[df[\"country\"] == selected_country]\n    \n    numerical_columns = filtered_df.select_dtypes('number').drop([\"year\",\"latitude\",\"longitude\"], axis=1)\n    \n    # KDE plots\n    fig, axes = plt.subplots(7, 3, figsize=(15, 15))\n    axes = axes.flatten()\n    for i, column in enumerate(numerical_columns.columns):\n        sns.kdeplot(data=numerical_columns, x=column, fill=True, color='skyblue', ax=axes[i])\n        axes[i].set_title(column)\n    for j in range(len(numerical_columns.columns), len(axes)):\n        axes[j].axis('off')\n    plt.tight_layout()\n    plt.show()\n\n    # Skewness table\n    skewness = numerical_columns.skew().sort_values(ascending=False)\n    skewness_df = skewness.reset_index()\n    skewness_df.columns = [\"Feature\", \"Skewness\"]\n\n    display(skewness_df)\n\n    # Take top 10 most skewed features\n    top_skewed = skewness_df.head(10)[\"Feature\"].tolist()\n\n    # --- Second part: deeper analysis tied to top skewed ---\n    @interact(selected_feature=top_skewed)\n    def skewness_analysis(selected_feature):\n        fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n\n        # 1. Histogram (raw)\n        sns.histplot(filtered_df[selected_feature], bins=50, kde=True, ax=axes[0])\n        axes[0].set_title(f\"{selected_feature} Distribution (Raw)\")\n\n        # 2. Histogram (log-transformed)\n        sns.histplot(np.log1p(filtered_df[selected_feature]), bins=50, kde=True, ax=axes[1], color=\"orange\")\n        axes[1].set_title(f\"{selected_feature} Distribution (Log1p)\")\n\n        # 3. Boxplot\n        sns.boxplot(x=filtered_df[selected_feature], ax=axes[2], color=\"red\")\n        axes[2].set_title(f\"{selected_feature} Boxplot\")\n\n        plt.tight_layout()\n        plt.show()\n\n        # Outlier countries\n        threshold = filtered_df[selected_feature].quantile(0.95)\n        outlier_countries = (\n            filtered_df[filtered_df[selected_feature] > threshold]\n            .groupby(\"country\")[selected_feature]\n            .count()\n            .sort_values(ascending=False)\n        )\n        print(f\"Countries contributing most to {selected_feature} skewness:\")\n        display(outlier_countries.head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:30:00.381478Z","iopub.execute_input":"2025-09-26T12:30:00.381745Z","iopub.status.idle":"2025-09-26T12:30:13.13901Z","shell.execute_reply.started":"2025-09-26T12:30:00.381722Z","shell.execute_reply":"2025-09-26T12:30:13.138453Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"#Top 10 COUNTRIES RANKING (basic_features)\n\nimport ipywidgets as widgets\nfrom IPython.display import display\n\ndef top_hot_cold(df, mode=\"Current Month\"):\n    # Determine mode\n    if mode == \"Current Month\":\n        current_month = pd.Timestamp.now().month\n        current_year = pd.Timestamp.now().year\n        data = df[(df['last_updated'].dt.month == current_month) &\n                  (df['last_updated'].dt.year == current_year)]\n        \n    else:\n        # All months = use full dataset\n        data = df.copy()\n\n    # Group and compute averages\n    top_hot = data.groupby(\"country\")[\"temperature_celsius\"].mean().sort_values(ascending=False).head(10)\n    top_cold = data.groupby(\"country\")[\"temperature_celsius\"].mean().sort_values(ascending=True).head(10)\n    longest_days = data.groupby(\"country\")[\"day_length_hours\"].mean().sort_values(ascending=False).head(10)\n    pm_2_5 = data.groupby(\"country\")[\"air_quality_PM2.5\"].mean().sort_values(ascending=False).head(10)\n    start_date = df[\"last_updated\"].max()\n\n    # Combine into one DataFrame\n    combined_df = pd.DataFrame({\n        'Cold(c)': top_cold.index, \n        'Mean_Temp_Cold': top_cold.values,\n        'Hot(c)': top_hot.index, \n        'Mean_Temp_Hot': top_hot.values,\n        \"Day_length\" : longest_days.index,\n        \"Mean_Length\" : longest_days.values,\n        \"PM2.5\" : pm_2_5.index,\n        \"Mean2.5\" : pm_2_5.values\n        \n    }, index=pd.Index(range(1, 11), name='Rank'))\n\n    display(combined_df)\n    \n\n# Dropdown widget\nmode_dropdown = widgets.Dropdown(\n    options=[\"Current Month\", \"All Months Average\"],\n    value=\"Current Month\",\n    description=\"View:\"\n)\n\nwidgets.interact(lambda mode: top_hot_cold(df, mode), mode=mode_dropdown)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:30:13.139707Z","iopub.execute_input":"2025-09-26T12:30:13.13989Z","iopub.status.idle":"2025-09-26T12:30:13.18648Z","shell.execute_reply.started":"2025-09-26T12:30:13.139876Z","shell.execute_reply":"2025-09-26T12:30:13.185861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Update with actual column names from print(world.columns)\nworld = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n\n# Compute average per country\nd_count= [\"latitude\", \"longitude\", \"year\"]\nwanted = df.select_dtypes(include=\"number\").drop(d_count, axis=1)\nwanted[\"country\"] = df[\"country\"]\navg_aqi = wanted.groupby(\"country\", as_index=False).mean()\n\n# Merge with shapefile\nworld = world.merge(avg_aqi, left_on=\"name\", right_on=\"country\", how=\"left\")\n\n\nexcluded = [\"name\", \"country\", \"iso_a3\", \"geometry\", \"pop_est\", \"gdp_md_est\", \"continent\"]\n\nfeatures = [col for col in world.columns if col not in excluded]\n\ndef plot_feature(feature):\n    if feature not in world.columns:\n        print(f\"❌ Column '{feature}' not found in world DataFrame. Available: {list(world.columns)}\")\n        return\n    \n    fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n\n    world.boundary.plot(ax=ax, linewidth=0.8, color=\"black\")\n    world.plot(\n        column=feature,\n        cmap=\"OrRd\",\n        legend=True,\n        ax=ax,\n        missing_kwds={\n            \"color\": \"lightgrey\",\n            \"edgecolor\": \"white\",\n            \"hatch\": \"///\",\n            \"label\": \"No data\",\n        }\n    )\n\n    ax.set_title(f\"Average {feature.replace('_',' ').title()} by Country\",\n                 fontsize=16, fontweight=\"bold\")\n    ax.axis(\"off\")\n    plt.show()\n\ninteract(\n    plot_feature,\n    feature=widgets.Dropdown(options=features, value=features[0], description=\"Feature:\")\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:30:13.187213Z","iopub.execute_input":"2025-09-26T12:30:13.187508Z","iopub.status.idle":"2025-09-26T12:30:15.288637Z","shell.execute_reply.started":"2025-09-26T12:30:13.187481Z","shell.execute_reply":"2025-09-26T12:30:15.287948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Lets see if there are any correlation among Air pollutants\n\n# Select pollutants\npollutants = [\"air_quality_PM2.5\", \"air_quality_PM10\", \"air_quality_Nitrogen_dioxide\", \n              \"air_quality_Sulphur_dioxide\", \"air_quality_Ozone\", \"air_quality_Carbon_Monoxide\"]\n\n# Correlation matrix\ncorr = df[pollutants].corr()\n\n# Heatmap\nplt.figure(figsize=(8,6))\nsns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\nplt.title(\"Correlation Among Air Pollutants\")\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:30:15.28936Z","iopub.execute_input":"2025-09-26T12:30:15.289571Z","iopub.status.idle":"2025-09-26T12:30:15.709729Z","shell.execute_reply.started":"2025-09-26T12:30:15.289555Z","shell.execute_reply":"2025-09-26T12:30:15.708975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Let's see how the air quality parameters perform in contrast with W.H.O limits\n\nwho_limits = {\n    \"air_quality_PM2.5\": 15,\n    \"air_quality_PM10\": 45,\n    \"air_quality_Nitrogen_dioxide\": 25,\n    \"air_quality_Sulphur_dioxide\": 40,\n    \"air_quality_Ozone\": 100,\n    \"air_quality_Carbon_Monoxide\": 4000\n}\n\nfor pollutant, limit in who_limits.items():\n    exceedance = (df[pollutant] > limit).mean() * 100\n    print(f\"{pollutant}: {exceedance:.1f}% of records exceed WHO guideline\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:31:17.647376Z","iopub.execute_input":"2025-09-26T12:31:17.648092Z","iopub.status.idle":"2025-09-26T12:31:17.656054Z","shell.execute_reply.started":"2025-09-26T12:31:17.64807Z","shell.execute_reply":"2025-09-26T12:31:17.655222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Lets see the countries that violates the most\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n\n# --- WHO limits ---\nWHO_PM25_LIMIT = 5     \nWHO_PM10_LIMIT = 15    \nWHO_NO2_LIMIT = 10     \nWHO_SO2_LIMIT = 40     \nWHO_O3_LIMIT = 100     \n\n# --- Aggregate by country ---\ncountry_avg = df.groupby(\"country\").agg({\n    \"air_quality_PM2.5\": \"mean\",\n    \"air_quality_PM10\": \"mean\",\n    \"air_quality_Nitrogen_dioxide\": \"mean\",\n    \"air_quality_Sulphur_dioxide\": \"mean\",\n    \"air_quality_Ozone\": \"mean\"\n}).reset_index()\n\n# --- Merge with world map ---\nworld = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\nworld = world.merge(country_avg, left_on=\"name\", right_on=\"country\", how=\"left\")\n\n# --- Pollutants dict ---\npollutants = {\n    \"PM2.5 (µg/m³)\": \"air_quality_PM2.5\",\n    \"PM10 (µg/m³)\": \"air_quality_PM10\",\n    \"NO₂ (µg/m³)\": \"air_quality_Nitrogen_dioxide\",\n    \"SO₂ (µg/m³)\": \"air_quality_Sulphur_dioxide\",\n    \"O₃ (µg/m³)\": \"air_quality_Ozone\"\n}\n\n# --- Base figure with 2 subplots: map + bar chart ---\nfig = make_subplots(\n    rows=1, cols=2,\n    column_widths=[0.7, 0.3],\n    subplot_titles=(\"Global Pollution Hotspots\", \"Top 5 Violators\"),\n    specs=[[{\"type\": \"choropleth\"}, {\"type\": \"bar\"}]]\n)\n\n# Default pollutant (PM2.5)\ndefault_col = list(pollutants.values())[0]\n\n# Choropleth map\nchoropleth = go.Choropleth(\n    geojson=world.__geo_interface__,\n    locations=world.index,\n    z=world[default_col],\n    colorscale=\"Reds\",\n    colorbar_title=\"µg/m³\",\n    marker_line_color=\"black\",\n    marker_line_width=0.2\n)\n\n# Top 5 bar chart\ntop5 = country_avg.nlargest(5, default_col)\nbar = go.Bar(\n    x=top5[default_col],\n    y=top5[\"country\"],\n    orientation=\"h\",\n    marker=dict(color=\"crimson\")\n)\n\n# Add traces\nfig.add_trace(choropleth, row=1, col=1)\nfig.add_trace(bar, row=1, col=2)\n\n# --- Dropdown menu ---\nbuttons = []\nfor label, col in pollutants.items():\n    # Top 5 for this pollutant\n    top5 = country_avg.nlargest(5, col)\n    buttons.append(dict(\n        method=\"update\",\n        label=label,\n        args=[\n            {\n                \"z\": [world[col], top5[col]], \n                \"x\": [None, top5[col]], \n                \"y\": [None, top5[\"country\"]]\n            },\n            {\"title\": f\"Global Air Quality Hotspots – {label}\"}\n        ]\n    ))\n\nfig.update_layout(\n    geo=dict(projection_type=\"natural earth\"),\n    updatemenus=[dict(\n        active=0,\n        buttons=buttons,\n        x=0.1, y=1.1,\n        xanchor=\"left\", yanchor=\"top\"\n    )],\n    height=600, width=1100,\n    showlegend=False\n)\n\nfig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:31:16.858256Z","iopub.execute_input":"2025-09-26T12:31:16.859042Z","iopub.status.idle":"2025-09-26T12:31:17.054141Z","shell.execute_reply.started":"2025-09-26T12:31:16.859022Z","shell.execute_reply":"2025-09-26T12:31:17.053521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Lets see if there are correlations between Weather and AQI values\n\n# Focus subset\n\ncol_to_corr = df.select_dtypes(\"number\").drop([\"year\"], axis = 1)\ncorr_cols = [\"temperature_celsius\", \"humidity\", \"air_quality_PM2.5\", \"air_quality_us-epa-index\", \"day_length_hours\"]\ncorr_matrix = col_to_corr.corr()\n\n# Heatmap\nplt.figure(figsize=(15,9))\nsns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\nplt.title(\"Correlation: Weather vs AirQuality vs Location\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:31:06.352724Z","iopub.execute_input":"2025-09-26T12:31:06.352982Z","iopub.status.idle":"2025-09-26T12:31:07.745721Z","shell.execute_reply.started":"2025-09-26T12:31:06.352964Z","shell.execute_reply":"2025-09-26T12:31:07.744833Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n**Time Series AnalysisTemperature vs Air Quality Parameters**\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport plotly.graph_objects as go\n\n# --- Ensure datetime ---\ndf[\"last_updated\"] = pd.to_datetime(df[\"last_updated\"])\n\n# --- Function to resample ---\ndef aggregate_data(freq, country=\"All\", param=\"air_quality_PM2.5\"):\n    if country != \"All\":\n        temp_df = df[df[\"country\"] == country]\n    else:\n        temp_df = df.copy()\n    \n    resampled = temp_df.resample(freq, on=\"last_updated\").agg({\n        \"temperature_celsius\": \"mean\",\n        param: \"mean\"\n    }).reset_index()\n    \n    return resampled\n\n# --- Initial defaults ---\nparam = \"air_quality_PM2.5\"\ncountry = \"All\"\nfreq = \"D\"  # Daily by default\ndata = aggregate_data(freq, country, param)\n\n# --- Base Figure ---\nfig = go.Figure()\n\n# Temperature trace\nfig.add_trace(go.Scatter(\n    x=data[\"last_updated\"], y=data[\"temperature_celsius\"],\n    mode=\"lines+markers\", name=\"Temperature (°C)\", line=dict(color=\"red\")\n))\n\n# AQI trace\nfig.add_trace(go.Scatter(\n    x=data[\"last_updated\"], y=data[param],\n    mode=\"lines+markers\", name=param, line=dict(color=\"blue\"), yaxis=\"y2\"\n))\n\n# Layout with dual y-axes\nfig.update_layout(\n    title=\"Weather–Pollution Interaction (Interactive)\",\n    xaxis=dict(title=\"Date\"),\n    yaxis=dict(title=\"Temperature (°C)\", color=\"red\"),\n    yaxis2=dict(title=f\"{param} (µg/m³)\", overlaying=\"y\", side=\"right\", color=\"blue\"),\n    height=600\n)\n\n# --- Dropdown options ---\ncountries = [\"All\"] + sorted(df[\"country\"].dropna().unique().tolist())\naq_params = [\"air_quality_PM2.5\", \"air_quality_PM10\",\n             \"air_quality_Nitrogen_dioxide\",\n             \"air_quality_Sulphur_dioxide\", \"air_quality_Ozone\"]\n\n# 1) Frequency buttons\nfreq_buttons = [\n    dict(label=\"Daily\", method=\"update\",\n         args=[{\"x\": [aggregate_data(\"D\", country, param)[\"last_updated\"],\n                      aggregate_data(\"D\", country, param)[\"last_updated\"]],\n                \"y\": [aggregate_data(\"D\", country, param)[\"temperature_celsius\"],\n                      aggregate_data(\"D\", country, param)[param]]},\n               {\"xaxis\": {\"title\": \"Date\"}}]),\n    dict(label=\"Weekly\", method=\"update\",\n         args=[{\"x\": [aggregate_data(\"W\", country, param)[\"last_updated\"],\n                      aggregate_data(\"W\", country, param)[\"last_updated\"]],\n                \"y\": [aggregate_data(\"W\", country, param)[\"temperature_celsius\"],\n                      aggregate_data(\"W\", country, param)[param]]},\n               {\"xaxis\": {\"title\": \"Week\"}}]),\n    dict(label=\"Monthly\", method=\"update\",\n         args=[{\"x\": [aggregate_data(\"M\", country, param)[\"last_updated\"],\n                      aggregate_data(\"M\", country, param)[\"last_updated\"]],\n                \"y\": [aggregate_data(\"M\", country, param)[\"temperature_celsius\"],\n                      aggregate_data(\"M\", country, param)[param]]},\n               {\"xaxis\": {\"title\": \"Month\"}}]),\n]\n\n# 2) Parameter buttons\nparam_buttons = [\n    dict(label=p, method=\"update\",\n         args=[{\"y\": [aggregate_data(freq, country, p)[\"temperature_celsius\"],\n                      aggregate_data(freq, country, p)[p]],\n                \"x\": [aggregate_data(freq, country, p)[\"last_updated\"],\n                      aggregate_data(freq, country, p)[\"last_updated\"]],\n                \"name\": [\"Temperature (°C)\", p]},\n               {\"yaxis2\": {\"title\": f\"{p} (µg/m³)\"}}])\n    for p in aq_params\n]\n\n# 3) Country buttons\ncountry_buttons = [\n    dict(label=c, method=\"update\",\n         args=[{\"y\": [aggregate_data(freq, c, param)[\"temperature_celsius\"],\n                      aggregate_data(freq, c, param)[param]],\n                \"x\": [aggregate_data(freq, c, param)[\"last_updated\"],\n                      aggregate_data(freq, c, param)[\"last_updated\"]],\n                \"name\": [\"Temperature (°C)\", param]}])\n    for c in countries\n]\n\n# --- Attach dropdowns ---\nfig.update_layout(\n    updatemenus=[\n        dict(buttons=freq_buttons, direction=\"down\", showactive=True, x=0.0, y=1.15, xanchor=\"left\", yanchor=\"top\"),\n        dict(buttons=param_buttons, direction=\"down\", showactive=True, x=0.25, y=1.15, xanchor=\"left\", yanchor=\"top\"),\n        dict(buttons=country_buttons, direction=\"down\", showactive=True, x=0.55, y=1.15, xanchor=\"left\", yanchor=\"top\"),\n    ]\n)\n\nfig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T12:30:18.188523Z","iopub.execute_input":"2025-09-26T12:30:18.188726Z","iopub.status.idle":"2025-09-26T12:30:29.509053Z","shell.execute_reply.started":"2025-09-26T12:30:18.18871Z","shell.execute_reply":"2025-09-26T12:30:29.508155Z"}},"outputs":[],"execution_count":null}]}